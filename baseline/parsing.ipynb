{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e5f289",
   "metadata": {},
   "source": [
    "# Скрапим и парсим данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9795b-29f0-4cc3-855f-f7b801dea4de",
   "metadata": {},
   "source": [
    "**Благодарим за разработку парсера - Александра Коробова (ЦТИИ ГПБ).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc79917",
   "metadata": {},
   "source": [
    "Машинное обучение без данных, как говорят, что компьютер без электричества. Любая, какая бы то ни было модель, не покажет стоящего результата, если данные будут плохого качества. А чем больше данных, тем больше вероятность, что из них можно вытащить что-либо полезное.\n",
    "\n",
    "Поэтому важно уметь (и иметь возможность) доставать новые данные. Например, **скрапить** — извлекать информацию с сайтов.\n",
    "\n",
    "Это можно сделать на языке Python, например, с помощью фреймворков `requests` или `selenium`. Первая библиотека позволяет «общаться» с веб-сервисом за счёт HTTP-запросов, а вторая моделирует действия реального пользователя.\n",
    "\n",
    "Однако за счёт одного запроса мы не сможем вытащить нужную нам информацию в удобном (главное, читаемом) виде, потому что результатом запроса может являться как html-код, так и текст типа json — необходимо обработать эти данные. Иначе говоря, **распарсить**, то есть автоматически обработать данные, поступаемые в сложно интерпретируемом формате, во что-то осознанное и систематизированное.\n",
    "\n",
    "Ниже посмотрим, как можно извлекать данные с сайтов с помощью запросов `requests`, распарсить их, собрать полученные данные в датасет и сохранить всё в удобной табличке. \n",
    "\n",
    "Здесь приведён сразу *сырой пример* программы, позволяющего парсить объявления о продаже квартир на сайте **Циан**. Некоторые части кода будут более подробно рассмотрены далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "import cfscrape\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "PAUSE_TIME = 5 # Увеличиваем интервалы отправки запросов — борьба с капчей\n",
    "CSV_NUMBER = 'test' # Постфикс названия создаваемой таблицы\n",
    "CSV_PATH = os.path.normpath(os.path.join(os.getcwd(), 'csv')) # Создаём папку 'csv' для записи создаваемых таблиц\n",
    "if not os.path.exists(CSV_PATH): # ...если такой не существовало ранее\n",
    "    os.mkdir(CSV_PATH)\n",
    "    print(f'Folder {CSV_PATH} has been created!')\n",
    "\n",
    "\n",
    "# Словарь некоторых городов с номерами, объявления по которым можно искать на Циан\n",
    "regions = {\n",
    "    'msk': 1, # Москва\n",
    "    'spb': 2, # Санкт–Петербург\n",
    "    'ekb': 4743, # Екатеринбург\n",
    "    'nsk': 4897, # Новосибирск\n",
    "    'kzn': 4777, # Казань\n",
    "    'nng': 4885, # Нижний Новгород\n",
    "}\n",
    "\n",
    "# Названия столбцов (header) будущей таблицы,\n",
    "# которые связываются с отобранными признаками в create_table()\n",
    "dataset = [\n",
    "            [ \n",
    "                'region',\n",
    "                'address',\n",
    "                'price',\n",
    "                'total_area',\n",
    "                'kitchen_area', \n",
    "                'living_area',\n",
    "                'rooms_count',\n",
    "                'floor', \n",
    "                'floors_number',\n",
    "                'build_date',\n",
    "                'isСomplete',\n",
    "                'complitation_year',\n",
    "                'house_material',\n",
    "                'parking',\n",
    "                'decoration',\n",
    "                'balcony',\n",
    "                'longitude', \n",
    "                'latitude',\n",
    "                'passenger_elevator', \n",
    "                'cargo_elevator', \n",
    "                'metro', \n",
    "                'metro_distance', \n",
    "                'metro_transport',\n",
    "                'district',\n",
    "                'is_apartments',\n",
    "                'is_auction'\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "\n",
    "# Функция для обработки пропусков и булевых значений\n",
    "def add_attr(attr):\n",
    "    if isinstance(attr, bool):\n",
    "        return int(attr)\n",
    "        \n",
    "    return attr if attr is not None else 'empty'\n",
    "\n",
    "\n",
    "# Функция для создания экземпляра класса запросов\n",
    "def get_session():\n",
    "    # Передаваемые параметры для экземпляра (как получить — туториал ниже)\n",
    "    \n",
    "#     headers = {\n",
    "#         'authority': 'api.cian.ru',\n",
    "#         'accept': '*/*',\n",
    "#         'accept-language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "#         'content-type': 'application/json',\n",
    "#         'cookie': '_CIAN_GK=8ad76c13-5d73-434f-a106-85e76bc875c2; _gcl_au=1.1.603512102.1709739126; login_mro_popup=1; tmr_lvid=fd128fd61fa70340de24133346787875; tmr_lvidTS=1709739125862; sopr_utm=%7B%22utm_source%22%3A+%22direct%22%2C+%22utm_medium%22%3A+%22None%22%7D; uxfb_usertype=searcher; uxs_uid=b08c1360-dbce-11ee-a235-dbd798ce88c8; _ym_uid=1709739127926818209; _ym_d=1709739127; _gid=GA1.2.1679918364.1709739127; adrcid=AqVeMksRrLuFDGWuGh5eHAA; afUserId=376096fb-0dea-4523-8b7d-b3a5bcc5e04b-p; AF_SYNC=1709739130749; cookie_agreement_accepted=1; _gpVisits={\"isFirstVisitDomain\":true,\"idContainer\":\"1000252B\"}; _ym_isad=2; session_region_id=1; session_main_town_region_id=1; my_home_tooltip_key=1; __cf_bm=xfCAkbpX9ppffyTsT4WWIO79gqKeezq_65L69zg7FyQ-1709836575-1.0.1.1-ip4jO9ORUzxF4nT29EAvddfrHOBsiCV2ESdzMtheO1WvBvkazkD8.KIfbht2NzeD7mvp1XhDrXTetG6eSz_v4Q; anti_bot=\"2|1:0|10:1709837263|8:anti_bot|44:eyJyZW1vdGVfaXAiOiAiMjEyLjE2NC42NS4yMDIifQ==|03fa3fbfbf2d89f2dcd6fa5bded6206894d6c04032651ca823bc2c358f01ed20\"; sopr_session=443ce283b49c41e9; _ga=GA1.2.890488983.1709739127; _dc_gtm_UA-30374201-1=1; _ym_visorc=b; _ga_3369S417EL=GS1.1.1709837259.11.1.1709837276.43.0.0',\n",
    "#         'origin': 'https://www.cian.ru',\n",
    "#         'referer': 'https://www.cian.ru/',\n",
    "#         'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n",
    "#         'sec-ch-ua-mobile': '?0',\n",
    "#         'sec-ch-ua-platform': '\"macOS\"',\n",
    "#         'sec-fetch-dest': 'empty',\n",
    "#         'sec-fetch-mode': 'cors',\n",
    "#         'sec-fetch-site': 'same-site',\n",
    "#         'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',\n",
    "#     }\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers = headers\n",
    "    return cfscrape.create_scraper(sess=session) # cfscrape — обход защиты от ботов Cloudflare\n",
    "\n",
    "\n",
    "# Записываем всё в файл формата .csv\n",
    "def recording_table():\n",
    "    try:\n",
    "        with open(os.path.join(CSV_PATH, f'data_{CSV_NUMBER}.csv'), mode='w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                for row in dataset:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "        print(f'The dataset is written in file \"data_{CSV_NUMBER}.csv\"')\n",
    "        return\n",
    "            \n",
    "    except Exception as error:\n",
    "        print('Recording error!\\n', traceback.format_exc())\n",
    "        sleep(PAUSE_TIME)\n",
    "        return\n",
    "    \n",
    "\n",
    "# Получаем формат json (питоновский dict) из нашего запроса Response        \n",
    "def get_json(session, region_name, cur_page):\n",
    "    # Параметры, которые отображаются в URL-запросе\n",
    "    # https://www.cian.ru/cat.php/?deal_type=sale&engine_version=2&offer_type=flat&region=1&\n",
    "    # room1=1&room2=1&room3=1&room4=1&room5=1&room6=1\n",
    "    json_data = {\n",
    "            'jsonQuery': {\n",
    "                '_type': 'flatsale',\n",
    "                'engine_version': {\n",
    "                    'type': 'term',\n",
    "                    'value': 2,\n",
    "                },\n",
    "                'region': {\n",
    "                    'type': 'terms',\n",
    "                    'value': [\n",
    "                        regions[region_name],\n",
    "                    ],\n",
    "                },\n",
    "                'room': {\n",
    "                    'type': 'terms',\n",
    "                    'value': [\n",
    "                        1,\n",
    "                        2,\n",
    "                        3,\n",
    "                        4,\n",
    "                        5,\n",
    "                        6,\n",
    "                    ],\n",
    "                },\n",
    "                'page': {\n",
    "                    'type': 'term',\n",
    "                    'value': cur_page,\n",
    "                },\n",
    "                # Можно задавать дополнительные атрибуты фильтрации объявлений\n",
    "                \n",
    "                # 'price': {\n",
    "                #     'type': 'range',\n",
    "                #     'value': {\n",
    "                #         'gte': min_price,\n",
    "                #         'lte': max_price,\n",
    "                #     },\n",
    "                # },\n",
    "            },\n",
    "        }\n",
    "        \n",
    "    # Получаем запрос с заданными параметрами\n",
    "    # Возвращаемое значение — bytes\n",
    "    try:\n",
    "        response = session.post('https://api.cian.ru/search-offers/v2/search-offers-desktop/',\n",
    "                                json=json_data)\n",
    "\n",
    "    except:\n",
    "        return f'oops! Error {response.status_code}'\n",
    "\n",
    "    # Получаем формат .json\n",
    "    if (\n",
    "        response.status_code != 204 and \n",
    "        response.headers[\"content-type\"].strip().startswith(\"application/json\")\n",
    "    ):\n",
    "        try:\n",
    "            return response.json()\n",
    "        except ValueError:\n",
    "            return f'oops! ValueError!'\n",
    "\n",
    "\n",
    "def create_table(region_name='msk', start_page=1, end_page=55, number_of_samples=100):\n",
    "    # В Циан выдаются страницы в диапазоне [1, 54]\n",
    "    if start_page < 1:\n",
    "        start_page = 1\n",
    "    if end_page > 55:\n",
    "        end_page = 55\n",
    "    \n",
    "    session = get_session()\n",
    "\n",
    "    cnt_samples = 0\n",
    "    for cur_page in tqdm(range(start_page, end_page)): # tqdm — выводим прогресс выполнения цикла\n",
    "        if cnt_samples >= number_of_samples:\n",
    "            break\n",
    "            \n",
    "        data = get_json(session, region_name, cur_page)\n",
    "        if data is None:\n",
    "            print('oops! Captcha!')\n",
    "            return\n",
    "        if isinstance(data, str):\n",
    "            print(data)\n",
    "            continue\n",
    "        \n",
    "        # Отбираем из большого словаря то, что нам нужно (можно и больше — смотри data)\n",
    "        for item in data['data']['offersSerialized']:\n",
    "            cur_item = [\n",
    "                    region_name,\n",
    "                    add_attr(item[\"geo\"][\"userInput\"]),\n",
    "                    add_attr(item['bargainTerms']['priceRur']),\n",
    "                    add_attr(item.get('totalArea')),\n",
    "                    add_attr(item.get('kitchenArea')),\n",
    "                    add_attr(item.get('livingArea')),\n",
    "                    add_attr(item.get('roomsCount')),\n",
    "                    add_attr(item.get('floorNumber')),\n",
    "                    add_attr(item['building'].get('floorsCount')),\n",
    "                    add_attr(item['building'].get('buildYear')),\n",
    "                    add_attr(item['building']['deadline']['isComplete'] if item['building'].get('deadline') is not None else None),\n",
    "                    add_attr(item['building']['deadline']['year'] if item['building'].get('deadline') is not None else None),\n",
    "                    add_attr(item['building'].get('materialType')),\n",
    "                    add_attr(item['building']['parking']['type'] if item['building'].get('parking') is not None else None),\n",
    "                    add_attr(item.get('decoration')),\n",
    "                    add_attr(item.get('balconiesCount')),\n",
    "                    add_attr(item['geo']['coordinates']['lng']),\n",
    "                    add_attr(item['geo']['coordinates']['lat']),\n",
    "                    add_attr(item['building'].get('passengerLiftsCount')),\n",
    "                    add_attr(item['building'].get('cargoLiftsCount')),\n",
    "                    add_attr(','.join([str(x['name']) for x in item['geo']['undergrounds']if x is not None])),\n",
    "                    add_attr(','.join([str(x['time']) for x in item['geo']['undergrounds'] if x is not None])),\n",
    "                    add_attr(','.join([str(x['transportType']) for x in item['geo']['undergrounds'] if x is not None])),\n",
    "                    add_attr(','.join([str(x['name']) for x in item['geo']['districts'] if x is not None])),\n",
    "                    add_attr(item.get('isApartments')), \n",
    "                    add_attr(item.get('isAuction'))\n",
    "                ]\n",
    "            \n",
    "            if cur_item not in dataset:\n",
    "                dataset.append(cur_item)\n",
    "                cnt_samples += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if cnt_samples >= number_of_samples:\n",
    "                break\n",
    "\n",
    "        print(f'{cnt_samples} / {number_of_samples} | page: {cur_page}')\n",
    "        sleep(PAUSE_TIME)\n",
    "                \n",
    "    recording_table()\n",
    "    return\n",
    "\n",
    "\n",
    "create_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389dbf9",
   "metadata": {},
   "source": [
    "**Методы программы:**\n",
    "\n",
    "* `add_attr` — для обработки пропусков и булевых значений; чтобы первые в табличке прописывались словом 'empty', а вторые были в бинарном виде;\n",
    "* `get_session` — метод, создающий экземпляр класса `requests.Session()`; отличие от обычного `requests` в том, что он позволяет сохранить определённые параметры запроса для сайта (помогает в борьбе с капчей за счёт использования cookie; что такое словари cookies и headers, а также туториал по тому, как их достать, — дальше;\n",
    "* `recording_table` — метод для записи получившейся таблицы на диск;\n",
    "* `get_json` — метод, которыq отправляет запросы на сайта Циана, обрабатывает полученные результаты и возвращает их в формате .json (в питоне хранится в виде типа `dict`);\n",
    "* `create_table` — основная функция — метод для обработки получающихся в `get_json` словарей и выделение из них необходимых нам признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0d560",
   "metadata": {},
   "source": [
    "## Чуть более подробно о параметрах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9085f8",
   "metadata": {},
   "source": [
    "Для начала мы в методе `get_session` создаем объект класса, с помощью которого будем передавать запросы на сайт Циана. В нём мы передаём следующие параметры через словарь `headers`. Его можно сгенерировать с помощью сторонних утилит! Ровно так же, как и `json_data` из метода `get_json`.\n",
    "\n",
    "Дело в том, что практически все сайты-агрегаторы — помимо кода html — хранят у себя в коде страницы уже готовый json, который можно отыскать для простоты генераций запросов, чтобы избежать проблем с парсингом html. :)\n",
    "\n",
    "В Циане это обстоит немного иначе: если нажать на их сайте кнопку «Найти» и выбрать нужные параметры, то сайт отправит запрос (аналогично тому, что мы отправляем на сам сайт) базе данных, с которой вернётся результат уже в формате `.json` — мы можем сделать это напрямую, заодно получив \n",
    "\n",
    "Более конкретно:\n",
    "\n",
    "1. Заходим, например, на Московский (можно и на любой другой, но могут возникнуть трудности) сайт Циана ([ссылка](https://www.cian.ru/)).\n",
    "2. Выбираем фильтры, по которым мы хотим формировать будущую табличку — это будущий словарь `json_data` (например, в примере выше выбрана продажа квартир ('flatsale') в Москве с комнатами от 1 до 6; при этом в запросе мы просматриваем страничку `cur_page`).\n",
    "3. Открываем панель разработчика (`Ctrl + Shift + I`, `Cmd + option + I` и т.п.) и переходим во вкладку «Сеть» («Network»).\n",
    "4. Нажима на поиск на сайте.\n",
    "5. Ищем запрос `search-offers-dekstop`; если на него нажать, то будет что-то вроде: `{data: {,…}, status: \"ok\"}`.\n",
    "6. Нажимаем правой кнопкой и копируем как `cURL`.\n",
    "7. Заходим на сайт [cURL Converter](https://curlconverter.com) и вставляем скопированное в пункте 6.\n",
    "8. Получаем необходимые (и готовые) словари `headers` и `json_data` — вы великолепны!\n",
    "\n",
    "**Замечение про капчу!**\n",
    "\n",
    "Использование `requests.Session()`, `cfscrape` и `sleep(PAUSE_TIME)` не ограничивают от того, что ваши запросы сайт расценит как активность робота и вывалит вам капчу вместо ответа — во избежание этого нужно писать более сложный код. Чтобы это поправить, нужно обновить параметр `cookie` словаря `json_data` перед очередным запуском кода. Как получить новое значение словаря? *Проделать пункты 1.—8., пройдя предварительно вручную проверку на то, что под вашим ip скрывается на робот*.\n",
    "\n",
    "**Замечение про замечание и всё остальное!**\n",
    "\n",
    "Всё изложенное выше претендует лишь на пример того, как можно собирать новые данные в интернете, и вовсе не выдаётся за абсолютно верный путь. Цель этого — передать идею и продемонстрировать функционал. Но всё, так или иначе, в ваших руках — пробуйте, ошибайтесь, набирайтесь опыта и, в конце концов, становитесь крутыми специалистами!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b175d4-fc66-46b3-9044-2e58c8b6cd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
